{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Fast.ai 2 \n",
        "This project is inherently open-ended in nature and I wanted to take this opportunity to explore machine learning as it is applied based on what we had previously explored in class through labs. So, the first question was what was I going to do as a project? I decided I would like to pick an applicable problem and using machine learning to explore it. That begs the question of the problem. I decided I wanted to stick to using computer vision like we did in MNIST since I was more familiar with it. Eventually, I decided to chose music genre recognition as the task, and fortunately Kaggle has a dataset just for this."
      ],
      "metadata": {
        "id": "JrBUlywQvdjj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C-oX08Drs5_"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',force_remount=True)\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBiP9KE1tddN"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from fastbook import *\n",
        "from fastai.vision.widgets import *\n",
        "from fastai.data.all import *\n",
        "from fastai.vision.all import *\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files \n",
        "import glob\n",
        "import cv2\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "import os \n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zblJV0-7fpF1"
      },
      "source": [
        "#Downloading data\n",
        "It definetly took a while to figure out how I was going to deal with the data in this case. I download all the data onto my personal computer and then uploaded it to Google Drive. That was simple enough, and after a little bit of research and playing around, I found the necessary tools to connect Google Colab and my Google Drive. For the first part of this project I decided to use the spectrograms given in the data set. I simply converted them to black and white and then normalized the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLNwM4Urz13q"
      },
      "outputs": [],
      "source": [
        "genres = ['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(0, len(genres)):\n",
        "  for flic in os.listdir('/content/drive/My Drive/music/images_original/' + genres[i] + '/'):\n",
        "    f = os.path.join('/content/drive/My Drive/music/images_original/' + genres[i] + '/',flic)\n",
        "    if os.path.isfile:\n",
        "      X.append([cv2.cvtColor((cv2.imread(f)), cv2.COLOR_BGR2GRAY)/255])\n",
        "      y.append(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luD8KAab4OXG"
      },
      "outputs": [],
      "source": [
        "num_classes = 10 \n",
        "X = (np.reshape(X, (999, 288, 432, 1)))\n",
        "y = keras.utils.to_categorical(y,num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XxkjNYX09yr"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.1, random_state=42)\n",
        "num_classes = 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I decided to use the keras library with a convulotional neural network based on my research. For MNIST in our class we used the most basic form of a neural network with just backpropogation. A CNN is similar in the aspect that it is also a neural network, however there also some extra steps prior to the actual neural network that are applied. Kernels are applied to the image repeatedly, producing new feature maps at each step. Finally, the feature map is flattened into a vector input that can be input into the neural network. Once in the neural network with the edited input, backpropogation occurs and the output is found. CNNs are currently state of the art for image recognition. Moreover, from my reseach I found keras to be one of most popular and effective libraries for CNNs. "
      ],
      "metadata": {
        "id": "YwvxmFxH_cGi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YGXDnt1flFN",
        "outputId": "16cca276-cfff-49a8-f20f-fe32a37f6ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 286, 430, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 143, 215, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 141, 213, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 70, 106, 64)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 474880)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 474880)            0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                4748810   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,767,626\n",
            "Trainable params: 4,767,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_shape = np.shape(X_train[1])\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzLpYLW19bFW",
        "outputId": "5dd63dc9-eaf9-4816-e7f5-309e10a22c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "6/6 [==============================] - 6s 973ms/step - loss: 6.4182 - accuracy: 0.1224 - val_loss: 2.6189 - val_accuracy: 0.2556\n",
            "Epoch 2/15\n",
            "6/6 [==============================] - 2s 401ms/step - loss: 2.4684 - accuracy: 0.1641 - val_loss: 2.2864 - val_accuracy: 0.1722\n",
            "Epoch 3/15\n",
            "6/6 [==============================] - 2s 399ms/step - loss: 2.2897 - accuracy: 0.1627 - val_loss: 2.2866 - val_accuracy: 0.1611\n",
            "Epoch 4/15\n",
            "6/6 [==============================] - 2s 401ms/step - loss: 2.2707 - accuracy: 0.1794 - val_loss: 2.2446 - val_accuracy: 0.1833\n",
            "Epoch 5/15\n",
            "6/6 [==============================] - 2s 401ms/step - loss: 2.2242 - accuracy: 0.1683 - val_loss: 2.1847 - val_accuracy: 0.1778\n",
            "Epoch 6/15\n",
            "6/6 [==============================] - 2s 401ms/step - loss: 2.1177 - accuracy: 0.2114 - val_loss: 2.1048 - val_accuracy: 0.2389\n",
            "Epoch 7/15\n",
            "6/6 [==============================] - 2s 402ms/step - loss: 1.9368 - accuracy: 0.3978 - val_loss: 1.9218 - val_accuracy: 0.3333\n",
            "Epoch 8/15\n",
            "6/6 [==============================] - 2s 405ms/step - loss: 1.6753 - accuracy: 0.5049 - val_loss: 1.7906 - val_accuracy: 0.3333\n",
            "Epoch 9/15\n",
            "6/6 [==============================] - 2s 405ms/step - loss: 1.4209 - accuracy: 0.6050 - val_loss: 1.6615 - val_accuracy: 0.4667\n",
            "Epoch 10/15\n",
            "6/6 [==============================] - 2s 405ms/step - loss: 1.2196 - accuracy: 0.6439 - val_loss: 1.4608 - val_accuracy: 0.5056\n",
            "Epoch 11/15\n",
            "6/6 [==============================] - 2s 406ms/step - loss: 1.0689 - accuracy: 0.7135 - val_loss: 1.3804 - val_accuracy: 0.5389\n",
            "Epoch 12/15\n",
            "6/6 [==============================] - 2s 407ms/step - loss: 0.8839 - accuracy: 0.7497 - val_loss: 1.3484 - val_accuracy: 0.5444\n",
            "Epoch 13/15\n",
            "6/6 [==============================] - 2s 406ms/step - loss: 0.7339 - accuracy: 0.8387 - val_loss: 1.2053 - val_accuracy: 0.6000\n",
            "Epoch 14/15\n",
            "6/6 [==============================] - 2s 409ms/step - loss: 0.6246 - accuracy: 0.8498 - val_loss: 1.1884 - val_accuracy: 0.6222\n",
            "Epoch 15/15\n",
            "6/6 [==============================] - 2s 405ms/step - loss: 0.5175 - accuracy: 0.8860 - val_loss: 1.1230 - val_accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4309b87710>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPwTn21h9oME",
        "outputId": "9e99a1f4-b763-4271-b4d8-667316d62090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.109246850013733\n",
            "Test accuracy: 0.6399999856948853\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = np.shape(X_train[1])\n",
        "\n",
        "model2 = keras.Sequential(\n",
        "    [\n",
        "     \n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "     \n",
        "\n",
        "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "     \n",
        "\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    \n",
        "\n",
        "        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhk8gHby5c8C",
        "outputId": "84556238-50b1-4fb6-d31e-435d500ebf3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 286, 430, 8)       80        \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 143, 215, 8)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 141, 213, 16)      1168      \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 70, 106, 16)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " input_13 (InputLayer)       multiple                  0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 68, 104, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 34, 52, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 32, 50, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 16, 25, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 14, 23, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 7, 11, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 9856)              0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 9856)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                98570     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 196,810\n",
            "Trainable params: 196,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 75\n",
        "\n",
        "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model2.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-38Mdqm57Cw",
        "outputId": "72d7111e-771a-453f-f6d1-640770791baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "6/6 [==============================] - 5s 425ms/step - loss: 2.3063 - accuracy: 0.1085 - val_loss: 2.3085 - val_accuracy: 0.0500\n",
            "Epoch 2/75\n",
            "6/6 [==============================] - 1s 175ms/step - loss: 2.2808 - accuracy: 0.1725 - val_loss: 2.2939 - val_accuracy: 0.1167\n",
            "Epoch 3/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 2.2051 - accuracy: 0.2128 - val_loss: 2.2057 - val_accuracy: 0.1278\n",
            "Epoch 4/75\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 2.0787 - accuracy: 0.2378 - val_loss: 2.0400 - val_accuracy: 0.2611\n",
            "Epoch 5/75\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 1.9382 - accuracy: 0.3018 - val_loss: 1.9791 - val_accuracy: 0.2333\n",
            "Epoch 6/75\n",
            "6/6 [==============================] - 1s 174ms/step - loss: 1.8849 - accuracy: 0.3268 - val_loss: 1.9484 - val_accuracy: 0.2889\n",
            "Epoch 7/75\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 1.8192 - accuracy: 0.3686 - val_loss: 1.8178 - val_accuracy: 0.3667\n",
            "Epoch 8/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 1.7136 - accuracy: 0.3825 - val_loss: 1.7531 - val_accuracy: 0.3833\n",
            "Epoch 9/75\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 1.6456 - accuracy: 0.4103 - val_loss: 1.6882 - val_accuracy: 0.4111\n",
            "Epoch 10/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 1.5646 - accuracy: 0.4367 - val_loss: 1.6709 - val_accuracy: 0.3833\n",
            "Epoch 11/75\n",
            "6/6 [==============================] - 1s 170ms/step - loss: 1.5082 - accuracy: 0.4826 - val_loss: 1.5517 - val_accuracy: 0.4278\n",
            "Epoch 12/75\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 1.4331 - accuracy: 0.5118 - val_loss: 1.4277 - val_accuracy: 0.5111\n",
            "Epoch 13/75\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 1.3401 - accuracy: 0.5063 - val_loss: 1.4556 - val_accuracy: 0.4611\n",
            "Epoch 14/75\n",
            "6/6 [==============================] - 1s 173ms/step - loss: 1.2979 - accuracy: 0.5396 - val_loss: 1.4383 - val_accuracy: 0.4833\n",
            "Epoch 15/75\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 1.2596 - accuracy: 0.5563 - val_loss: 1.3005 - val_accuracy: 0.5611\n",
            "Epoch 16/75\n",
            "6/6 [==============================] - 1s 173ms/step - loss: 1.2535 - accuracy: 0.5786 - val_loss: 1.4137 - val_accuracy: 0.4889\n",
            "Epoch 17/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 1.1858 - accuracy: 0.5702 - val_loss: 1.3814 - val_accuracy: 0.5444\n",
            "Epoch 18/75\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 1.1523 - accuracy: 0.6078 - val_loss: 1.2748 - val_accuracy: 0.5611\n",
            "Epoch 19/75\n",
            "6/6 [==============================] - 1s 174ms/step - loss: 1.0812 - accuracy: 0.6064 - val_loss: 1.2715 - val_accuracy: 0.5889\n",
            "Epoch 20/75\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 1.0367 - accuracy: 0.6439 - val_loss: 1.2830 - val_accuracy: 0.5778\n",
            "Epoch 21/75\n",
            "6/6 [==============================] - 1s 173ms/step - loss: 1.0005 - accuracy: 0.6328 - val_loss: 1.2408 - val_accuracy: 0.5944\n",
            "Epoch 22/75\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 0.9443 - accuracy: 0.6662 - val_loss: 1.3814 - val_accuracy: 0.5444\n",
            "Epoch 23/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 0.9369 - accuracy: 0.6676 - val_loss: 1.1895 - val_accuracy: 0.5722\n",
            "Epoch 24/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 0.8770 - accuracy: 0.6926 - val_loss: 1.2099 - val_accuracy: 0.5556\n",
            "Epoch 25/75\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 0.8659 - accuracy: 0.7065 - val_loss: 1.1659 - val_accuracy: 0.6222\n",
            "Epoch 26/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 0.8566 - accuracy: 0.7191 - val_loss: 1.1747 - val_accuracy: 0.6056\n",
            "Epoch 27/75\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 0.8097 - accuracy: 0.7246 - val_loss: 1.3577 - val_accuracy: 0.5833\n",
            "Epoch 28/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 0.8331 - accuracy: 0.7121 - val_loss: 1.3154 - val_accuracy: 0.5611\n",
            "Epoch 29/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 0.8060 - accuracy: 0.7177 - val_loss: 1.1499 - val_accuracy: 0.6556\n",
            "Epoch 30/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 0.7503 - accuracy: 0.7385 - val_loss: 1.1645 - val_accuracy: 0.6389\n",
            "Epoch 31/75\n",
            "6/6 [==============================] - 1s 170ms/step - loss: 0.7230 - accuracy: 0.7288 - val_loss: 1.2343 - val_accuracy: 0.6611\n",
            "Epoch 32/75\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 0.7449 - accuracy: 0.7413 - val_loss: 1.2440 - val_accuracy: 0.6500\n",
            "Epoch 33/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 0.6895 - accuracy: 0.7691 - val_loss: 1.1699 - val_accuracy: 0.6111\n",
            "Epoch 34/75\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 0.6555 - accuracy: 0.7636 - val_loss: 1.1369 - val_accuracy: 0.6556\n",
            "Epoch 35/75\n",
            "6/6 [==============================] - 1s 170ms/step - loss: 0.5883 - accuracy: 0.7942 - val_loss: 1.0974 - val_accuracy: 0.6444\n",
            "Epoch 36/75\n",
            "6/6 [==============================] - 1s 207ms/step - loss: 0.5364 - accuracy: 0.8303 - val_loss: 1.1951 - val_accuracy: 0.6500\n",
            "Epoch 37/75\n",
            "6/6 [==============================] - 1s 180ms/step - loss: 0.5221 - accuracy: 0.8122 - val_loss: 1.1435 - val_accuracy: 0.6667\n",
            "Epoch 38/75\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 0.5003 - accuracy: 0.8303 - val_loss: 1.0811 - val_accuracy: 0.6833\n",
            "Epoch 39/75\n",
            "6/6 [==============================] - 1s 170ms/step - loss: 0.5188 - accuracy: 0.8192 - val_loss: 1.1298 - val_accuracy: 0.6222\n",
            "Epoch 40/75\n",
            "6/6 [==============================] - 1s 170ms/step - loss: 0.5236 - accuracy: 0.8122 - val_loss: 1.0717 - val_accuracy: 0.6722\n",
            "Epoch 41/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 0.4603 - accuracy: 0.8581 - val_loss: 1.2876 - val_accuracy: 0.6389\n",
            "Epoch 42/75\n",
            "6/6 [==============================] - 1s 173ms/step - loss: 0.4420 - accuracy: 0.8498 - val_loss: 1.2885 - val_accuracy: 0.6333\n",
            "Epoch 43/75\n",
            "6/6 [==============================] - 1s 173ms/step - loss: 0.4623 - accuracy: 0.8359 - val_loss: 1.1610 - val_accuracy: 0.6722\n",
            "Epoch 44/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 0.4623 - accuracy: 0.8387 - val_loss: 1.4302 - val_accuracy: 0.6333\n",
            "Epoch 45/75\n",
            "6/6 [==============================] - 1s 175ms/step - loss: 0.4431 - accuracy: 0.8484 - val_loss: 1.3200 - val_accuracy: 0.6444\n",
            "Epoch 46/75\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 0.3632 - accuracy: 0.8929 - val_loss: 1.2588 - val_accuracy: 0.6500\n",
            "Epoch 47/75\n",
            "6/6 [==============================] - 1s 170ms/step - loss: 0.3544 - accuracy: 0.8846 - val_loss: 1.2749 - val_accuracy: 0.6444\n",
            "Epoch 48/75\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 0.3637 - accuracy: 0.8804 - val_loss: 1.3119 - val_accuracy: 0.6556\n",
            "Epoch 49/75\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 0.3135 - accuracy: 0.9013 - val_loss: 1.1632 - val_accuracy: 0.6611\n",
            "Epoch 50/75\n",
            "6/6 [==============================] - 1s 170ms/step - loss: 0.3565 - accuracy: 0.8804 - val_loss: 1.2125 - val_accuracy: 0.6778\n",
            "Epoch 51/75\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 0.2710 - accuracy: 0.9124 - val_loss: 1.3558 - val_accuracy: 0.6667\n",
            "Epoch 52/75\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 0.2384 - accuracy: 0.9263 - val_loss: 1.3971 - val_accuracy: 0.6722\n",
            "Epoch 53/75\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 0.2702 - accuracy: 0.9082 - val_loss: 1.2907 - val_accuracy: 0.6722\n",
            "Epoch 54/75\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 0.2030 - accuracy: 0.9360 - val_loss: 1.2703 - val_accuracy: 0.6778\n",
            "Epoch 55/75\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 0.2084 - accuracy: 0.9235 - val_loss: 1.3536 - val_accuracy: 0.6556\n",
            "Epoch 56/75\n",
            "6/6 [==============================] - 1s 170ms/step - loss: 0.2395 - accuracy: 0.9138 - val_loss: 1.2340 - val_accuracy: 0.6833\n",
            "Epoch 57/75\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 0.2297 - accuracy: 0.9235 - val_loss: 1.4329 - val_accuracy: 0.6611\n",
            "Epoch 58/75\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 0.1878 - accuracy: 0.9471 - val_loss: 1.4450 - val_accuracy: 0.6500\n",
            "Epoch 59/75\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 0.1728 - accuracy: 0.9527 - val_loss: 1.3670 - val_accuracy: 0.6722\n",
            "Epoch 60/75\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 0.1622 - accuracy: 0.9485 - val_loss: 1.2683 - val_accuracy: 0.6722\n",
            "Epoch 61/75\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 0.1728 - accuracy: 0.9374 - val_loss: 1.6285 - val_accuracy: 0.6389\n",
            "Epoch 62/75\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 0.1551 - accuracy: 0.9527 - val_loss: 1.4411 - val_accuracy: 0.6722\n",
            "Epoch 63/75\n",
            "6/6 [==============================] - 1s 166ms/step - loss: 0.1703 - accuracy: 0.9527 - val_loss: 1.4110 - val_accuracy: 0.6722\n",
            "Epoch 64/75\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 0.1343 - accuracy: 0.9569 - val_loss: 1.4827 - val_accuracy: 0.6667\n",
            "Epoch 65/75\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 0.1217 - accuracy: 0.9638 - val_loss: 1.5160 - val_accuracy: 0.6889\n",
            "Epoch 66/75\n",
            "6/6 [==============================] - 1s 173ms/step - loss: 0.1175 - accuracy: 0.9652 - val_loss: 1.4477 - val_accuracy: 0.6722\n",
            "Epoch 67/75\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 0.1144 - accuracy: 0.9652 - val_loss: 1.4197 - val_accuracy: 0.6722\n",
            "Epoch 68/75\n",
            "6/6 [==============================] - 1s 178ms/step - loss: 0.0937 - accuracy: 0.9777 - val_loss: 1.4827 - val_accuracy: 0.6833\n",
            "Epoch 69/75\n",
            "6/6 [==============================] - 1s 172ms/step - loss: 0.0856 - accuracy: 0.9777 - val_loss: 1.6247 - val_accuracy: 0.6667\n",
            "Epoch 70/75\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 0.0872 - accuracy: 0.9764 - val_loss: 1.4997 - val_accuracy: 0.6722\n",
            "Epoch 71/75\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 0.0775 - accuracy: 0.9805 - val_loss: 1.6959 - val_accuracy: 0.6556\n",
            "Epoch 72/75\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 0.0727 - accuracy: 0.9777 - val_loss: 1.6498 - val_accuracy: 0.6833\n",
            "Epoch 73/75\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 0.0630 - accuracy: 0.9750 - val_loss: 1.6874 - val_accuracy: 0.6667\n",
            "Epoch 74/75\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 0.0722 - accuracy: 0.9791 - val_loss: 1.9528 - val_accuracy: 0.6722\n",
            "Epoch 75/75\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 0.0937 - accuracy: 0.9638 - val_loss: 1.8123 - val_accuracy: 0.6444\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f42de5f35d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model2.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDDKBLn87tYd",
        "outputId": "8ca48f56-ab25-4a6f-d618-b5f6a4613892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 2.015120267868042\n",
            "Test accuracy: 0.6200000047683716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results for basic data\n",
        "When approaching this project to explore this data I wanted to try a variation of models with manipulation of the data set to find what would produce the most effective model. With the data set of spectrograms given, I found fairly dissapointing accuracy on my testing data for both models ~63%. The first model was with less layers and the second with more, interesting enough the results appear to be fairly similar. One thing I found was that the more complex the neural network, the more epochs would be needed to train it. This is explemfied when comparing the accuracy on the training data of the two models. "
      ],
      "metadata": {
        "id": "Sb478osGAp_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import librosa\n",
        "!pip install pydub\n",
        "import pydub\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play \n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from PIL import Image\n",
        "drive.mount('/content/drive/',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "eiCBetZEWkXG",
        "outputId": "24fb6de6-ea9d-443c-de94-b7a8f4ecc90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1f381fd882c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_agg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigureCanvasAgg\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mFigureCanvas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'drive' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2 Messing with the training data\n",
        "Alright, so clearly the accuracy using the spectrograms given was not enough for high accuracy. Now, it's time to take another approach. I decided on creating a larger data set by segmenting the audio given in the data set and then producing spectrograms, that would be again edited with grayscale and normalized. This was a process in itself, figuring out how to do this. Moreover, initially, I planned to experiment with different audio clip lengths to see if there was an optimum, balancing the larger data set vs less information from a shorter audio clip. However, I quickly ran into some problems: the largest being the time in took to create all these new spectrograms from clips. It took roughly a day of running to create all the spectrograms for the audio length of 5 seconds. I was going to start with audio lengths of 3 seconds, but I realized that, that would take way too long, so I decided on the 5 second length. This is unfortunate, since I think I would've gotten more insight on what makes the model work better, but I still think in the end I have a good picture of what would've worked better. Nevertheless, the time loading the data gave me time to do other assignments! I also ran into issues, however, with creating data (only one file oddly enough) and used a try-catch method to deal with it."
      ],
      "metadata": {
        "id": "zPtNhctxC1cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genres = ['disco','hiphop','jazz','metal','pop','reggae','blues','classical','country','rock']\n",
        "\n",
        "splitX, splity = [], []\n",
        "\n",
        "for i in range(0, len(genres)):\n",
        "  for song in os.listdir('/content/drive/My Drive/music/genres_original/' + genres[i] + '/'):\n",
        "    songfile = os.path.join('/content/drive/My Drive/music/genres_original/' + genres[i] + '/',song)\n",
        "    if os.path.isfile:\n",
        "      for songlength in range(0,6):\n",
        "        if '.wav' in song:\n",
        "          path = os.path.join('/content/drive/My Drive/music/genres_original/' + genres[i] + '/',song[:song.index(\".wav\")])\n",
        "          \n",
        "          if os.path.exists(path) == False:\n",
        "            os.makedirs(path)\n",
        "\n",
        "          clip = os.path.join(path + '/' +str(songlength) + '.wav')\n",
        "          try: \n",
        "            if os.path.exists(clip) == False:\n",
        "              bound1 = 5*(songlength)*1000\n",
        "              bound2 = 5*(songlength+1)*1000\n",
        "\n",
        "              audio = AudioSegment.from_wav(songfile)\n",
        "              audiosegment = audio[bound1:bound2]\n",
        "\n",
        "              audiosegment.export(clip,format='wav')\n",
        "\n",
        "              y,sr = librosa.load(clip,duration=5)\n",
        "              spectrogram = librosa.feature.melspectrogram(y=y,sr=sr)\n",
        "\n",
        "              fig = plt.Figure()\n",
        "              canvas = FigureCanvas(fig)\n",
        "              p = plt.imshow(librosa.power_to_db(spectrogram,ref=np.max))\n",
        "              imgpath = os.path.join(path + '/' +str(songlength) + '.png')\n",
        "\n",
        "              if os.path.exists(imgpath) == False:\n",
        "                plt.savefig(imgpath)\n",
        "\n",
        "            imgpath = os.path.join(path + '/' +str(songlength) + '.png')\n",
        "            if os.path.exists(imgpath) == False:\n",
        "              y,sr = librosa.load(clip,duration=5)\n",
        "              spectrogram = librosa.feature.melspectrogram(y=y,sr=sr)\n",
        "\n",
        "              fig = plt.Figure()\n",
        "              canvas = FigureCanvas(fig)\n",
        "              p = plt.imshow(librosa.power_to_db(spectrogram,ref=np.max))\n",
        "              plt.savefig(imgpath)\n",
        "\n",
        "            print(imgpath,np.shape(splitX))\n",
        "            splitX.append([cv2.cvtColor(cv2.resize(cv2.imread(imgpath),(300,200),interpolation=cv2.INTER_AREA), cv2.COLOR_BGR2GRAY)/255])\n",
        "            splity.append(i)\n",
        "\n",
        "          except: \n",
        "            print(clip)\n",
        "          \n"
      ],
      "metadata": {
        "id": "h2_9YgFMRmif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10 \n",
        "print(np.shape(splitX))\n",
        "splitX = (np.reshape(splitX, (5994, 300, 200, 1)))\n",
        "splity = keras.utils.to_categorical(splity,num_classes)\n",
        "\n",
        "sX_train, sX_test, sy_train, sy_test = train_test_split(  splitX, splity, test_size=0.1, random_state=42)\n",
        "num_classes = 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuOlnHXViMGa",
        "outputId": "b702bd3e-77a1-4ea0-c3d4-c39d1079a388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5994, 1, 300, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = np.shape(sX_train[1])\n",
        "\n",
        "smodel = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "smodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivIUVkG1ij7s",
        "outputId": "7429ee4b-ac0d-4873-8e90-b43c4c0d5834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 298, 198, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 149, 99, 32)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 147, 97, 64)       18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 73, 48, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 224256)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 224256)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                2242570   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,261,386\n",
            "Trainable params: 2,261,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "smodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "smodel.fit(sX_train, sy_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-JwUAKfinEo",
        "outputId": "532aae69-8718-4ea0-e275-8926a37a3922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "34/34 [==============================] - 190s 5s/step - loss: 2.5234 - accuracy: 0.2176 - val_loss: 1.7737 - val_accuracy: 0.4013\n",
            "Epoch 2/15\n",
            "34/34 [==============================] - 199s 6s/step - loss: 1.4013 - accuracy: 0.5367 - val_loss: 1.1546 - val_accuracy: 0.5811\n",
            "Epoch 3/15\n",
            "34/34 [==============================] - 188s 6s/step - loss: 1.0429 - accuracy: 0.6287 - val_loss: 1.0067 - val_accuracy: 0.6682\n",
            "Epoch 4/15\n",
            "34/34 [==============================] - 186s 5s/step - loss: 0.8453 - accuracy: 0.7152 - val_loss: 1.0549 - val_accuracy: 0.6487\n",
            "Epoch 5/15\n",
            "34/34 [==============================] - 194s 6s/step - loss: 0.7559 - accuracy: 0.7469 - val_loss: 0.7483 - val_accuracy: 0.7405\n",
            "Epoch 6/15\n",
            "34/34 [==============================] - 190s 6s/step - loss: 0.6266 - accuracy: 0.7930 - val_loss: 0.6678 - val_accuracy: 0.7739\n",
            "Epoch 7/15\n",
            "34/34 [==============================] - 189s 6s/step - loss: 0.5851 - accuracy: 0.8072 - val_loss: 0.6659 - val_accuracy: 0.7627\n",
            "Epoch 8/15\n",
            "34/34 [==============================] - 189s 6s/step - loss: 0.5050 - accuracy: 0.8413 - val_loss: 0.6563 - val_accuracy: 0.7822\n",
            "Epoch 9/15\n",
            "34/34 [==============================] - 190s 6s/step - loss: 0.4570 - accuracy: 0.8498 - val_loss: 0.7007 - val_accuracy: 0.7563\n",
            "Epoch 10/15\n",
            "34/34 [==============================] - 195s 6s/step - loss: 0.4201 - accuracy: 0.8654 - val_loss: 0.5426 - val_accuracy: 0.8063\n",
            "Epoch 11/15\n",
            "34/34 [==============================] - 192s 6s/step - loss: 0.3386 - accuracy: 0.8980 - val_loss: 0.5682 - val_accuracy: 0.7989\n",
            "Epoch 12/15\n",
            "34/34 [==============================] - 193s 6s/step - loss: 0.3083 - accuracy: 0.9096 - val_loss: 0.5290 - val_accuracy: 0.8082\n",
            "Epoch 13/15\n",
            "34/34 [==============================] - 194s 6s/step - loss: 0.2720 - accuracy: 0.9244 - val_loss: 0.5143 - val_accuracy: 0.8137\n",
            "Epoch 14/15\n",
            "34/34 [==============================] - 194s 6s/step - loss: 0.2534 - accuracy: 0.9251 - val_loss: 0.5421 - val_accuracy: 0.8184\n",
            "Epoch 15/15\n",
            "34/34 [==============================] - 195s 6s/step - loss: 0.2236 - accuracy: 0.9363 - val_loss: 0.5558 - val_accuracy: 0.8109\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0631a33150>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = smodel.evaluate(sX_test, sy_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXkPGRGoiwLm",
        "outputId": "10d82787-5403-4119-d974-aa0ab5457f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.5067570209503174\n",
            "Test accuracy: 0.8366666436195374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = np.shape(sX_train[1])\n",
        "\n",
        "smodel2 = keras.Sequential(\n",
        "    [\n",
        "     \n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "     \n",
        "\n",
        "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "     \n",
        "\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    \n",
        "\n",
        "        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "smodel2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6T3HjsXi2Ul",
        "outputId": "8cd5f198-ada5-42a8-bb35-ad62d552e5ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 298, 198, 8)       80        \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 149, 99, 8)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 147, 97, 16)       1168      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 73, 48, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " input_3 (InputLayer)        multiple                  0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 71, 46, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 35, 23, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 33, 21, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 14, 8, 128)        73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 7, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3584)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3584)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                35850     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,090\n",
            "Trainable params: 134,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 75\n",
        "\n",
        "smodel2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "smodel2.fit(sX_train, sy_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3laT3RcjAkK",
        "outputId": "279c1f2c-6b18-439f-e856-fe2e7c51c044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "34/34 [==============================] - 82s 2s/step - loss: 2.0807 - accuracy: 0.1963 - val_loss: 1.9119 - val_accuracy: 0.2178\n",
            "Epoch 2/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 1.7193 - accuracy: 0.3555 - val_loss: 1.5222 - val_accuracy: 0.4754\n",
            "Epoch 3/75\n",
            "34/34 [==============================] - 85s 2s/step - loss: 1.2966 - accuracy: 0.5180 - val_loss: 1.1750 - val_accuracy: 0.5459\n",
            "Epoch 4/75\n",
            "34/34 [==============================] - 86s 3s/step - loss: 1.0841 - accuracy: 0.5954 - val_loss: 1.0446 - val_accuracy: 0.6237\n",
            "Epoch 5/75\n",
            "34/34 [==============================] - 85s 2s/step - loss: 0.9869 - accuracy: 0.6364 - val_loss: 0.9471 - val_accuracy: 0.6580\n",
            "Epoch 6/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.9392 - accuracy: 0.6572 - val_loss: 0.9548 - val_accuracy: 0.6599\n",
            "Epoch 7/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.8759 - accuracy: 0.6820 - val_loss: 0.8454 - val_accuracy: 0.7016\n",
            "Epoch 8/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.8244 - accuracy: 0.7124 - val_loss: 0.8131 - val_accuracy: 0.7071\n",
            "Epoch 9/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.8274 - accuracy: 0.7006 - val_loss: 0.7948 - val_accuracy: 0.7442\n",
            "Epoch 10/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.7452 - accuracy: 0.7400 - val_loss: 0.7366 - val_accuracy: 0.7581\n",
            "Epoch 11/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.7120 - accuracy: 0.7530 - val_loss: 0.6894 - val_accuracy: 0.7627\n",
            "Epoch 12/75\n",
            "34/34 [==============================] - 85s 3s/step - loss: 0.6992 - accuracy: 0.7502 - val_loss: 0.7237 - val_accuracy: 0.7479\n",
            "Epoch 13/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.6578 - accuracy: 0.7650 - val_loss: 0.6373 - val_accuracy: 0.7841\n",
            "Epoch 14/75\n",
            "34/34 [==============================] - 85s 2s/step - loss: 0.6280 - accuracy: 0.7794 - val_loss: 0.6721 - val_accuracy: 0.7665\n",
            "Epoch 15/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.6208 - accuracy: 0.7831 - val_loss: 0.6483 - val_accuracy: 0.7665\n",
            "Epoch 16/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.5821 - accuracy: 0.7928 - val_loss: 0.5884 - val_accuracy: 0.7952\n",
            "Epoch 17/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.5454 - accuracy: 0.8116 - val_loss: 0.6878 - val_accuracy: 0.7238\n",
            "Epoch 18/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.5326 - accuracy: 0.8183 - val_loss: 0.5323 - val_accuracy: 0.8230\n",
            "Epoch 19/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.5110 - accuracy: 0.8255 - val_loss: 0.6003 - val_accuracy: 0.7748\n",
            "Epoch 20/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.4984 - accuracy: 0.8246 - val_loss: 0.5261 - val_accuracy: 0.8174\n",
            "Epoch 21/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.4805 - accuracy: 0.8306 - val_loss: 0.5460 - val_accuracy: 0.8119\n",
            "Epoch 22/75\n",
            "34/34 [==============================] - 82s 2s/step - loss: 0.4851 - accuracy: 0.8368 - val_loss: 0.5668 - val_accuracy: 0.8156\n",
            "Epoch 23/75\n",
            "34/34 [==============================] - 82s 2s/step - loss: 0.4665 - accuracy: 0.8380 - val_loss: 0.4875 - val_accuracy: 0.8313\n",
            "Epoch 24/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.4112 - accuracy: 0.8561 - val_loss: 0.4652 - val_accuracy: 0.8415\n",
            "Epoch 25/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.4057 - accuracy: 0.8586 - val_loss: 0.4733 - val_accuracy: 0.8313\n",
            "Epoch 26/75\n",
            "34/34 [==============================] - 87s 3s/step - loss: 0.3806 - accuracy: 0.8674 - val_loss: 0.4609 - val_accuracy: 0.8434\n",
            "Epoch 27/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.3721 - accuracy: 0.8705 - val_loss: 0.4621 - val_accuracy: 0.8350\n",
            "Epoch 28/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.3771 - accuracy: 0.8702 - val_loss: 0.4730 - val_accuracy: 0.8406\n",
            "Epoch 29/75\n",
            "34/34 [==============================] - 82s 2s/step - loss: 0.3707 - accuracy: 0.8746 - val_loss: 0.4647 - val_accuracy: 0.8462\n",
            "Epoch 30/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.3428 - accuracy: 0.8811 - val_loss: 0.4279 - val_accuracy: 0.8526\n",
            "Epoch 31/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.3225 - accuracy: 0.8881 - val_loss: 0.4154 - val_accuracy: 0.8647\n",
            "Epoch 32/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.3253 - accuracy: 0.8867 - val_loss: 0.4280 - val_accuracy: 0.8554\n",
            "Epoch 33/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.3043 - accuracy: 0.8964 - val_loss: 0.4230 - val_accuracy: 0.8582\n",
            "Epoch 34/75\n",
            "34/34 [==============================] - 82s 2s/step - loss: 0.3034 - accuracy: 0.8948 - val_loss: 0.4162 - val_accuracy: 0.8563\n",
            "Epoch 35/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.3089 - accuracy: 0.8971 - val_loss: 0.5139 - val_accuracy: 0.8248\n",
            "Epoch 36/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.2995 - accuracy: 0.8948 - val_loss: 0.4185 - val_accuracy: 0.8563\n",
            "Epoch 37/75\n",
            "34/34 [==============================] - 82s 2s/step - loss: 0.2712 - accuracy: 0.9092 - val_loss: 0.4122 - val_accuracy: 0.8545\n",
            "Epoch 38/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.2547 - accuracy: 0.9089 - val_loss: 0.3916 - val_accuracy: 0.8601\n",
            "Epoch 39/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.2509 - accuracy: 0.9112 - val_loss: 0.4437 - val_accuracy: 0.8554\n",
            "Epoch 40/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.2553 - accuracy: 0.9089 - val_loss: 0.4064 - val_accuracy: 0.8582\n",
            "Epoch 41/75\n",
            "34/34 [==============================] - 83s 2s/step - loss: 0.2595 - accuracy: 0.9085 - val_loss: 0.4065 - val_accuracy: 0.8591\n",
            "Epoch 42/75\n",
            "34/34 [==============================] - 84s 2s/step - loss: 0.2295 - accuracy: 0.9200 - val_loss: 0.4054 - val_accuracy: 0.8638\n",
            "Epoch 43/75\n",
            "34/34 [==============================] - 80s 2s/step - loss: 0.2206 - accuracy: 0.9219 - val_loss: 0.3746 - val_accuracy: 0.8758\n",
            "Epoch 44/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.2059 - accuracy: 0.9300 - val_loss: 0.3885 - val_accuracy: 0.8758\n",
            "Epoch 45/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.2023 - accuracy: 0.9319 - val_loss: 0.3781 - val_accuracy: 0.8777\n",
            "Epoch 46/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1951 - accuracy: 0.9346 - val_loss: 0.3486 - val_accuracy: 0.8906\n",
            "Epoch 47/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1696 - accuracy: 0.9430 - val_loss: 0.3768 - val_accuracy: 0.8749\n",
            "Epoch 48/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1820 - accuracy: 0.9381 - val_loss: 0.4122 - val_accuracy: 0.8665\n",
            "Epoch 49/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1683 - accuracy: 0.9435 - val_loss: 0.3903 - val_accuracy: 0.8777\n",
            "Epoch 50/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.1573 - accuracy: 0.9455 - val_loss: 0.3774 - val_accuracy: 0.8767\n",
            "Epoch 51/75\n",
            "34/34 [==============================] - 81s 2s/step - loss: 0.1726 - accuracy: 0.9388 - val_loss: 0.4355 - val_accuracy: 0.8554\n",
            "Epoch 52/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.1559 - accuracy: 0.9458 - val_loss: 0.3694 - val_accuracy: 0.8777\n",
            "Epoch 53/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.1327 - accuracy: 0.9567 - val_loss: 0.3791 - val_accuracy: 0.8842\n",
            "Epoch 54/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.1340 - accuracy: 0.9562 - val_loss: 0.3902 - val_accuracy: 0.8767\n",
            "Epoch 55/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.1213 - accuracy: 0.9592 - val_loss: 0.3671 - val_accuracy: 0.8860\n",
            "Epoch 56/75\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.1448 - accuracy: 0.9504 - val_loss: 0.4298 - val_accuracy: 0.8851\n",
            "Epoch 57/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.1634 - accuracy: 0.9444 - val_loss: 0.3754 - val_accuracy: 0.8842\n",
            "Epoch 58/75\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.1208 - accuracy: 0.9585 - val_loss: 0.3617 - val_accuracy: 0.8943\n",
            "Epoch 59/75\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.1191 - accuracy: 0.9555 - val_loss: 0.4052 - val_accuracy: 0.8795\n",
            "Epoch 60/75\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.1219 - accuracy: 0.9546 - val_loss: 0.4012 - val_accuracy: 0.8823\n",
            "Epoch 61/75\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.1155 - accuracy: 0.9599 - val_loss: 0.3806 - val_accuracy: 0.8851\n",
            "Epoch 62/75\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.1153 - accuracy: 0.9632 - val_loss: 0.4011 - val_accuracy: 0.8832\n",
            "Epoch 63/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.1287 - accuracy: 0.9548 - val_loss: 0.4215 - val_accuracy: 0.8730\n",
            "Epoch 64/75\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.1034 - accuracy: 0.9634 - val_loss: 0.3765 - val_accuracy: 0.8897\n",
            "Epoch 65/75\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.0864 - accuracy: 0.9699 - val_loss: 0.3807 - val_accuracy: 0.8934\n",
            "Epoch 66/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.0863 - accuracy: 0.9687 - val_loss: 0.3895 - val_accuracy: 0.8823\n",
            "Epoch 67/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.0856 - accuracy: 0.9736 - val_loss: 0.3824 - val_accuracy: 0.8971\n",
            "Epoch 68/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.0781 - accuracy: 0.9729 - val_loss: 0.4081 - val_accuracy: 0.8860\n",
            "Epoch 69/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.0759 - accuracy: 0.9757 - val_loss: 0.4111 - val_accuracy: 0.8934\n",
            "Epoch 70/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.0925 - accuracy: 0.9666 - val_loss: 0.4162 - val_accuracy: 0.8851\n",
            "Epoch 71/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.0727 - accuracy: 0.9743 - val_loss: 0.3890 - val_accuracy: 0.8888\n",
            "Epoch 72/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.1015 - accuracy: 0.9627 - val_loss: 0.4092 - val_accuracy: 0.8906\n",
            "Epoch 73/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.0825 - accuracy: 0.9722 - val_loss: 0.3764 - val_accuracy: 0.8981\n",
            "Epoch 74/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.0710 - accuracy: 0.9757 - val_loss: 0.3930 - val_accuracy: 0.8916\n",
            "Epoch 75/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.0686 - accuracy: 0.9757 - val_loss: 0.3923 - val_accuracy: 0.8888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f062df60f90>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = smodel2.evaluate(sX_test, sy_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78cYneEUjGHM",
        "outputId": "667b70cc-3a5d-46a2-9911-e49164ab46b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.3914753794670105\n",
            "Test accuracy: 0.8883333206176758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Audio Segment results + Reformating data\n",
        "First off one can notice that the accuracy is significantly better in with the new data (accuracies of 83% and 89%). The more complex CNN did yield better results, and cemented my observation earlier that more complex models take more epochs to train. I also realized that I improperly reformated the data here. So, I ran into issues with loading the data due to RAM limited on Google Colab. With the inital spectrogram image size (800x1200), at around the point of ~1650 images (6000 total in this data set), the runtime would crash. The solution to this was to rescale the images down, although this may also confound the experiment. I did that, however, I realized I accidently scaled it to (300x200) and wanted to see if this made a differenece. Another thing to note is that the spectrograms contained axes and white space, which cropping out could've have possibly ameliorated. Nevertheless, I procedeed with the same data set except scaled properly down to (200x300). "
      ],
      "metadata": {
        "id": "AVNXNsw5EVtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genres = ['disco','hiphop','jazz','metal','pop','reggae','blues','classical','country','rock']\n",
        "\n",
        "splitX, splity = [], []\n",
        "\n",
        "for i in range(0, len(genres)):\n",
        "  for song in os.listdir('/content/drive/My Drive/music/genres_original/' + genres[i] + '/'):\n",
        "    songfile = os.path.join('/content/drive/My Drive/music/genres_original/' + genres[i] + '/',song)\n",
        "    if os.path.isfile:\n",
        "      for songlength in range(0,6):\n",
        "        if '.wav' in song:\n",
        "          path = os.path.join('/content/drive/My Drive/music/genres_original/' + genres[i] + '/',song[:song.index(\".wav\")])\n",
        "          \n",
        "          if os.path.exists(path) == False:\n",
        "            os.makedirs(path)\n",
        "\n",
        "          clip = os.path.join(path + '/' +str(songlength) + '.wav')\n",
        "          try: \n",
        "            if os.path.exists(clip) == False:\n",
        "              bound1 = 5*(songlength)*1000\n",
        "              bound2 = 5*(songlength+1)*1000\n",
        "\n",
        "              audio = AudioSegment.from_wav(songfile)\n",
        "              audiosegment = audio[bound1:bound2]\n",
        "\n",
        "              audiosegment.export(clip,format='wav')\n",
        "\n",
        "              y,sr = librosa.load(clip,duration=5)\n",
        "              spectrogram = librosa.feature.melspectrogram(y=y,sr=sr)\n",
        "\n",
        "              fig = plt.Figure()\n",
        "              canvas = FigureCanvas(fig)\n",
        "              p = plt.imshow(librosa.power_to_db(spectrogram,ref=np.max))\n",
        "              imgpath = os.path.join(path + '/' +str(songlength) + '.png')\n",
        "\n",
        "              if os.path.exists(imgpath) == False:\n",
        "                plt.savefig(imgpath)\n",
        "\n",
        "            imgpath = os.path.join(path + '/' +str(songlength) + '.png')\n",
        "            if os.path.exists(imgpath) == False:\n",
        "              y,sr = librosa.load(clip,duration=5)\n",
        "              spectrogram = librosa.feature.melspectrogram(y=y,sr=sr)\n",
        "\n",
        "              fig = plt.Figure()\n",
        "              canvas = FigureCanvas(fig)\n",
        "              p = plt.imshow(librosa.power_to_db(spectrogram,ref=np.max))\n",
        "              plt.savefig(imgpath)\n",
        "\n",
        "            splitX.append([cv2.cvtColor(cv2.resize(cv2.imread(imgpath),(200,300),interpolation=cv2.INTER_AREA), cv2.COLOR_BGR2GRAY)/255])\n",
        "            splity.append(i)\n",
        "\n",
        "          except: \n",
        "            print(clip)\n",
        "          \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtrE4sRZjIeq",
        "outputId": "cbe31125-beb5-43f5-d2d3-4301dae44f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/music/genres_original/jazz/jazz.00054/0.wav\n",
            "/content/drive/My Drive/music/genres_original/jazz/jazz.00054/1.wav\n",
            "/content/drive/My Drive/music/genres_original/jazz/jazz.00054/2.wav\n",
            "/content/drive/My Drive/music/genres_original/jazz/jazz.00054/3.wav\n",
            "/content/drive/My Drive/music/genres_original/jazz/jazz.00054/4.wav\n",
            "/content/drive/My Drive/music/genres_original/jazz/jazz.00054/5.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10 \n",
        "print(np.shape(splitX))\n",
        "splitX = (np.reshape(splitX, (5994, 300, 200, 1)))\n",
        "splity = keras.utils.to_categorical(splity,num_classes)\n",
        "\n",
        "sX_train, sX_test, sy_train, sy_test = train_test_split(  splitX, splity, test_size=0.1, random_state=42)\n",
        "num_classes = 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnZwJ36bf6Dk",
        "outputId": "e0a29b00-177c-49f9-cc82-c1144c26437e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5994, 1, 300, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genres = ['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(0, len(genres)):\n",
        "  for flic in os.listdir('/content/drive/My Drive/music/images_original/' + genres[i] + '/'):\n",
        "    f = os.path.join('/content/drive/My Drive/music/images_original/' + genres[i] + '/',flic)\n",
        "    if os.path.isfile:\n",
        "      X.append([cv2.cvtColor(cv2.resize((cv2.imread(f)),(200,300),interpolation=cv2.INTER_AREA), cv2.COLOR_BGR2GRAY)/255])\n",
        "      y.append(i)\n"
      ],
      "metadata": {
        "id": "hltGQTPgC5Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10 \n",
        "X = (np.reshape(X, (999, 300, 200, 1)))\n",
        "y = keras.utils.to_categorical(y,num_classes)"
      ],
      "metadata": {
        "id": "ViM9kkzBDNI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.1, random_state=42)\n",
        "num_classes = 10\n"
      ],
      "metadata": {
        "id": "TUvp5rMtDtl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = np.shape(sX_train[1])\n",
        "\n",
        "smodelv2 = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "smodelv2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUwLyCVTgDOq",
        "outputId": "1cc1166f-81e3-4e04-8971-f55fcb5d40c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 298, 198, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 149, 99, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 147, 97, 64)       18496     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 73, 48, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 224256)            0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 224256)            0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2242570   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,261,386\n",
            "Trainable params: 2,261,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "smodelv2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "smodelv2.fit(sX_train, sy_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsB6Xy_AgORR",
        "outputId": "ad5444b9-87f7-40f7-cf4e-0cdc6aa8122d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "34/34 [==============================] - 207s 6s/step - loss: 2.3172 - accuracy: 0.3082 - val_loss: 1.4651 - val_accuracy: 0.4930\n",
            "Epoch 2/15\n",
            "34/34 [==============================] - 192s 6s/step - loss: 1.1746 - accuracy: 0.5861 - val_loss: 0.9858 - val_accuracy: 0.6654\n",
            "Epoch 3/15\n",
            "34/34 [==============================] - 189s 6s/step - loss: 0.8662 - accuracy: 0.7027 - val_loss: 0.7682 - val_accuracy: 0.7507\n",
            "Epoch 4/15\n",
            "34/34 [==============================] - 201s 6s/step - loss: 0.6561 - accuracy: 0.7910 - val_loss: 0.6919 - val_accuracy: 0.7563\n",
            "Epoch 5/15\n",
            "34/34 [==============================] - 195s 6s/step - loss: 0.5639 - accuracy: 0.8204 - val_loss: 0.6827 - val_accuracy: 0.7600\n",
            "Epoch 6/15\n",
            "34/34 [==============================] - 195s 6s/step - loss: 0.4826 - accuracy: 0.8459 - val_loss: 0.5927 - val_accuracy: 0.7924\n",
            "Epoch 7/15\n",
            "34/34 [==============================] - 206s 6s/step - loss: 0.4441 - accuracy: 0.8489 - val_loss: 0.6205 - val_accuracy: 0.7878\n",
            "Epoch 8/15\n",
            "34/34 [==============================] - 196s 6s/step - loss: 0.3804 - accuracy: 0.8830 - val_loss: 0.5878 - val_accuracy: 0.7841\n",
            "Epoch 9/15\n",
            "34/34 [==============================] - 196s 6s/step - loss: 0.3251 - accuracy: 0.9017 - val_loss: 0.5870 - val_accuracy: 0.8007\n",
            "Epoch 10/15\n",
            "34/34 [==============================] - 195s 6s/step - loss: 0.2921 - accuracy: 0.9094 - val_loss: 0.5356 - val_accuracy: 0.8091\n",
            "Epoch 11/15\n",
            "34/34 [==============================] - 197s 6s/step - loss: 0.2596 - accuracy: 0.9265 - val_loss: 0.5225 - val_accuracy: 0.8193\n",
            "Epoch 12/15\n",
            "34/34 [==============================] - 196s 6s/step - loss: 0.2162 - accuracy: 0.9451 - val_loss: 0.5124 - val_accuracy: 0.8221\n",
            "Epoch 13/15\n",
            "34/34 [==============================] - 196s 6s/step - loss: 0.1878 - accuracy: 0.9495 - val_loss: 0.5398 - val_accuracy: 0.8174\n",
            "Epoch 14/15\n",
            "34/34 [==============================] - 196s 6s/step - loss: 0.1737 - accuracy: 0.9546 - val_loss: 0.5433 - val_accuracy: 0.8044\n",
            "Epoch 15/15\n",
            "34/34 [==============================] - 196s 6s/step - loss: 0.1329 - accuracy: 0.9715 - val_loss: 0.5138 - val_accuracy: 0.8193\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f062effe050>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = smodelv2.evaluate(sX_test, sy_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ2-pmWHgWNi",
        "outputId": "9ab972c5-99e6-415c-c666-bd9cb4bd2847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.48728057742118835\n",
            "Test accuracy: 0.8333333134651184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = smodelv2.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyQjwkXkDmLm",
        "outputId": "8a176873-304c-4838-9e39-eeebd3f45ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 23.221847534179688\n",
            "Test accuracy: 0.17000000178813934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = np.shape(sX_train[1])\n",
        "\n",
        "smodel2v2 = keras.Sequential(\n",
        "    [\n",
        "     \n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "     \n",
        "\n",
        "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "     \n",
        "\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    \n",
        "\n",
        "        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "smodel2v2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqVExv04gZ21",
        "outputId": "dcdebea1-d649-4a60-8cc0-ccc69f8631f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_11 (Conv2D)          (None, 298, 198, 8)       80        \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 149, 99, 8)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 147, 97, 16)       1168      \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 73, 48, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " input_7 (InputLayer)        multiple                  0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 71, 46, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 35, 23, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 33, 21, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 16, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 14, 8, 128)        73856     \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 7, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 3584)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3584)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                35850     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,090\n",
            "Trainable params: 134,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 75\n",
        "\n",
        "smodel2v2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "smodel2v2.fit(sX_train, sy_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpPAGMHMgf8e",
        "outputId": "007dcf18-9a3d-4bf4-8222-d041d75e2286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "34/34 [==============================] - 80s 2s/step - loss: 2.0915 - accuracy: 0.2046 - val_loss: 1.9101 - val_accuracy: 0.3234\n",
            "Epoch 2/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 1.7202 - accuracy: 0.3446 - val_loss: 1.5144 - val_accuracy: 0.4560\n",
            "Epoch 3/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 1.4533 - accuracy: 0.4565 - val_loss: 1.3958 - val_accuracy: 0.4708\n",
            "Epoch 4/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 1.3277 - accuracy: 0.5092 - val_loss: 1.2337 - val_accuracy: 0.5589\n",
            "Epoch 5/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 1.1769 - accuracy: 0.5652 - val_loss: 1.1773 - val_accuracy: 0.5468\n",
            "Epoch 6/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 1.0996 - accuracy: 0.5951 - val_loss: 1.0457 - val_accuracy: 0.6098\n",
            "Epoch 7/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 1.0430 - accuracy: 0.6216 - val_loss: 1.0525 - val_accuracy: 0.6006\n",
            "Epoch 8/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.9821 - accuracy: 0.6292 - val_loss: 0.9831 - val_accuracy: 0.6339\n",
            "Epoch 9/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.9316 - accuracy: 0.6591 - val_loss: 0.9441 - val_accuracy: 0.6487\n",
            "Epoch 10/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.8852 - accuracy: 0.6813 - val_loss: 0.9046 - val_accuracy: 0.6673\n",
            "Epoch 11/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.8356 - accuracy: 0.7008 - val_loss: 0.8145 - val_accuracy: 0.7108\n",
            "Epoch 12/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.7858 - accuracy: 0.7261 - val_loss: 0.8083 - val_accuracy: 0.7081\n",
            "Epoch 13/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.7775 - accuracy: 0.7363 - val_loss: 0.7986 - val_accuracy: 0.7146\n",
            "Epoch 14/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.7712 - accuracy: 0.7203 - val_loss: 0.8064 - val_accuracy: 0.7108\n",
            "Epoch 15/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.7127 - accuracy: 0.7479 - val_loss: 0.7642 - val_accuracy: 0.7349\n",
            "Epoch 16/75\n",
            "34/34 [==============================] - 80s 2s/step - loss: 0.6576 - accuracy: 0.7738 - val_loss: 0.6516 - val_accuracy: 0.7794\n",
            "Epoch 17/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.6291 - accuracy: 0.7805 - val_loss: 0.7355 - val_accuracy: 0.7368\n",
            "Epoch 18/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.6072 - accuracy: 0.7942 - val_loss: 0.6551 - val_accuracy: 0.7831\n",
            "Epoch 19/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.5516 - accuracy: 0.8121 - val_loss: 0.6267 - val_accuracy: 0.7924\n",
            "Epoch 20/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.5332 - accuracy: 0.8181 - val_loss: 0.5758 - val_accuracy: 0.8026\n",
            "Epoch 21/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.4775 - accuracy: 0.8329 - val_loss: 0.5813 - val_accuracy: 0.7989\n",
            "Epoch 22/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.4804 - accuracy: 0.8378 - val_loss: 0.5183 - val_accuracy: 0.8258\n",
            "Epoch 23/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.4416 - accuracy: 0.8470 - val_loss: 0.4834 - val_accuracy: 0.8489\n",
            "Epoch 24/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.4175 - accuracy: 0.8586 - val_loss: 0.5346 - val_accuracy: 0.8258\n",
            "Epoch 25/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.4246 - accuracy: 0.8535 - val_loss: 0.4882 - val_accuracy: 0.8434\n",
            "Epoch 26/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.3982 - accuracy: 0.8635 - val_loss: 0.5080 - val_accuracy: 0.8387\n",
            "Epoch 27/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.3749 - accuracy: 0.8753 - val_loss: 0.5203 - val_accuracy: 0.8258\n",
            "Epoch 28/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.3699 - accuracy: 0.8718 - val_loss: 0.4685 - val_accuracy: 0.8480\n",
            "Epoch 29/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.3669 - accuracy: 0.8714 - val_loss: 0.5008 - val_accuracy: 0.8323\n",
            "Epoch 30/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.3464 - accuracy: 0.8760 - val_loss: 0.4804 - val_accuracy: 0.8387\n",
            "Epoch 31/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.3502 - accuracy: 0.8830 - val_loss: 0.4404 - val_accuracy: 0.8582\n",
            "Epoch 32/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.3050 - accuracy: 0.8920 - val_loss: 0.4506 - val_accuracy: 0.8610\n",
            "Epoch 33/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.2961 - accuracy: 0.8941 - val_loss: 0.4345 - val_accuracy: 0.8610\n",
            "Epoch 34/75\n",
            "34/34 [==============================] - 76s 2s/step - loss: 0.3018 - accuracy: 0.8918 - val_loss: 0.4712 - val_accuracy: 0.8582\n",
            "Epoch 35/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.2771 - accuracy: 0.9059 - val_loss: 0.4786 - val_accuracy: 0.8508\n",
            "Epoch 36/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.2843 - accuracy: 0.8983 - val_loss: 0.4551 - val_accuracy: 0.8545\n",
            "Epoch 37/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.2705 - accuracy: 0.9061 - val_loss: 0.4198 - val_accuracy: 0.8638\n",
            "Epoch 38/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.2363 - accuracy: 0.9228 - val_loss: 0.4468 - val_accuracy: 0.8693\n",
            "Epoch 39/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.2377 - accuracy: 0.9143 - val_loss: 0.4196 - val_accuracy: 0.8767\n",
            "Epoch 40/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.2526 - accuracy: 0.9085 - val_loss: 0.4334 - val_accuracy: 0.8619\n",
            "Epoch 41/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.2108 - accuracy: 0.9254 - val_loss: 0.3991 - val_accuracy: 0.8684\n",
            "Epoch 42/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.2276 - accuracy: 0.9187 - val_loss: 0.5378 - val_accuracy: 0.8323\n",
            "Epoch 43/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.2505 - accuracy: 0.9145 - val_loss: 0.4552 - val_accuracy: 0.8675\n",
            "Epoch 44/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.2238 - accuracy: 0.9221 - val_loss: 0.4581 - val_accuracy: 0.8563\n",
            "Epoch 45/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.2272 - accuracy: 0.9249 - val_loss: 0.4514 - val_accuracy: 0.8628\n",
            "Epoch 46/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1831 - accuracy: 0.9374 - val_loss: 0.4878 - val_accuracy: 0.8536\n",
            "Epoch 47/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.2079 - accuracy: 0.9207 - val_loss: 0.3988 - val_accuracy: 0.8712\n",
            "Epoch 48/75\n",
            "34/34 [==============================] - 82s 2s/step - loss: 0.1694 - accuracy: 0.9423 - val_loss: 0.4213 - val_accuracy: 0.8749\n",
            "Epoch 49/75\n",
            "34/34 [==============================] - 77s 2s/step - loss: 0.1639 - accuracy: 0.9446 - val_loss: 0.4097 - val_accuracy: 0.8693\n",
            "Epoch 50/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1607 - accuracy: 0.9418 - val_loss: 0.4172 - val_accuracy: 0.8749\n",
            "Epoch 51/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1523 - accuracy: 0.9490 - val_loss: 0.4080 - val_accuracy: 0.8740\n",
            "Epoch 52/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1420 - accuracy: 0.9516 - val_loss: 0.4165 - val_accuracy: 0.8749\n",
            "Epoch 53/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.1535 - accuracy: 0.9446 - val_loss: 0.3979 - val_accuracy: 0.8675\n",
            "Epoch 54/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1689 - accuracy: 0.9414 - val_loss: 0.4144 - val_accuracy: 0.8786\n",
            "Epoch 55/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1340 - accuracy: 0.9555 - val_loss: 0.4041 - val_accuracy: 0.8712\n",
            "Epoch 56/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.1430 - accuracy: 0.9499 - val_loss: 0.4294 - val_accuracy: 0.8721\n",
            "Epoch 57/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1195 - accuracy: 0.9590 - val_loss: 0.4102 - val_accuracy: 0.8721\n",
            "Epoch 58/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.1201 - accuracy: 0.9578 - val_loss: 0.5243 - val_accuracy: 0.8601\n",
            "Epoch 59/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.1312 - accuracy: 0.9537 - val_loss: 0.4082 - val_accuracy: 0.8749\n",
            "Epoch 60/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1152 - accuracy: 0.9620 - val_loss: 0.4035 - val_accuracy: 0.8842\n",
            "Epoch 61/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1112 - accuracy: 0.9611 - val_loss: 0.3920 - val_accuracy: 0.8851\n",
            "Epoch 62/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.0927 - accuracy: 0.9664 - val_loss: 0.3958 - val_accuracy: 0.8832\n",
            "Epoch 63/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.0956 - accuracy: 0.9678 - val_loss: 0.4130 - val_accuracy: 0.8749\n",
            "Epoch 64/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.0951 - accuracy: 0.9692 - val_loss: 0.4811 - val_accuracy: 0.8591\n",
            "Epoch 65/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1202 - accuracy: 0.9594 - val_loss: 0.4487 - val_accuracy: 0.8712\n",
            "Epoch 66/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.1002 - accuracy: 0.9643 - val_loss: 0.4124 - val_accuracy: 0.8758\n",
            "Epoch 67/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.0797 - accuracy: 0.9738 - val_loss: 0.4743 - val_accuracy: 0.8730\n",
            "Epoch 68/75\n",
            "34/34 [==============================] - 78s 2s/step - loss: 0.0811 - accuracy: 0.9708 - val_loss: 0.4033 - val_accuracy: 0.8814\n",
            "Epoch 69/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.0770 - accuracy: 0.9738 - val_loss: 0.4413 - val_accuracy: 0.8601\n",
            "Epoch 70/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.0816 - accuracy: 0.9733 - val_loss: 0.4555 - val_accuracy: 0.8879\n",
            "Epoch 71/75\n",
            "34/34 [==============================] - 80s 2s/step - loss: 0.1131 - accuracy: 0.9567 - val_loss: 0.4276 - val_accuracy: 0.8795\n",
            "Epoch 72/75\n",
            "34/34 [==============================] - 80s 2s/step - loss: 0.0814 - accuracy: 0.9733 - val_loss: 0.4130 - val_accuracy: 0.8786\n",
            "Epoch 73/75\n",
            "34/34 [==============================] - 80s 2s/step - loss: 0.0723 - accuracy: 0.9764 - val_loss: 0.4585 - val_accuracy: 0.8749\n",
            "Epoch 74/75\n",
            "34/34 [==============================] - 79s 2s/step - loss: 0.0823 - accuracy: 0.9729 - val_loss: 0.4394 - val_accuracy: 0.8860\n",
            "Epoch 75/75\n",
            "34/34 [==============================] - 80s 2s/step - loss: 0.0799 - accuracy: 0.9738 - val_loss: 0.3996 - val_accuracy: 0.8814\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f062b288b90>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = smodel2v2.evaluate(sX_test, sy_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdxBKj2WgjOu",
        "outputId": "ec3faa27-142a-4478-c076-3126f9eb3113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.4118407666683197\n",
            "Test accuracy: 0.8799999952316284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "The results here are fairly similar oddly enough, meaning the scaling was pretty much a nonfactor. I decided to also try to use the original test set with these models, and got terrible accuracy. I attribute this to the difference in spectrograms: when inspecting the spectrograms, there is a stark difference in the images in the original data set and this data set. I am not completely sure why, but perhaps it has to do with the tools used to produce them. Regardless, using these models on the other data that is formatted differently is like comparing apples to oranges, or rather classifying oranges from a model training on apples. \n",
        "\n",
        "Although, I was not able to conduct the experimentation with the audio length that i would have liked to have done, I suspect that the 3 second duration would've produced better results. One may notice the drastic improvement in results from the first part and second part of my exploration (~63 to nearly 90%), and I attribute this mostly due to the increase in the size of the data set. I am not sure whether the 3 second duration would have been inherently better for the model, but I feel confident saying the 4000 extra spectrograms would've helped the model. Again, perhaps a longer duration with equal samples would be the best. This really demonstrated to me the importance of data set size in neural networks and the methods in which one manipulate their data to get a larger data set. The neeed for more epoches for more complex models was again cemented in this part of the project as well.\n",
        "\n",
        "I really enjoyed the project overall. It was definitely very intimidating starting this project. Having little experience in the implementation of libraries and machine learning in general means creating even a simple model appear burdensome. But, having done this project, everything feels much more within my grasp. That does not mean everything was easy, and I often found myself on what felt like wild goose chases searching for solutions online, but rather everything is surmountable. This project taught me to teach myself in a way and find resources to figure these out. I am excited going forward exploring CS and machine learning and projects like these give me the confidence of experience with actual application. AI as a class at TJ has made me want to pursue CS as a major in college, and being at TJ pursuing CS can feel sometimes intimidating. But having gone through this class, I feel better knowing that if I am willing to work hard and perserve CS is one of the most rewarding and interesting subjects. As this is the final project of the class I'd like to thank you for the opportunity, I'm very grateful for having this class as an option and only wish I could've taken it junior year such that I could've taken ML senior year. Thank you! "
      ],
      "metadata": {
        "id": "UKFDlqDlFpGG"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}